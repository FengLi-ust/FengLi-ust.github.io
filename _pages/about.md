---
permalink: /
title: About Me
excerpt: "Feng Li's Homepage"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm the first year PhD student at the Hong Kong University of Science and Technology, advised by Prof. [Heung-Yeung Shum](https://scholar.google.com/citations?user=9akH-n8AAAAJ&hl=zh-CN) and Prof. [Lionel M. Ni](https://scholar.google.com/citations?user=OzMYwDIAAAAJ&hl=zh-CN). I am currently an intern at [International Digital Economy Academy (IDEA)](https://idea.edu.cn/), advised by Prof. [Lei Zhang](https://www.leizhang.org/).

**Research Interests**

* Computer Vision, Object Detection, Multi-modal


# üî• News
- *2022.03*: &nbsp;We release a survey Vision-Language Intelligence: Tasks, Representation Learning, and Large Models;
- *2022.03*: &nbsp;DN-DETR: Accelerate DETR Training by Introducing Query DeNoising is accepted by CVPR 2022 with score 112;

# üìù Publications 

<!-- <div class='paper-box'>
<div class='paper-box-text' markdown="1"> -->

* DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection.  
Hao Zhang*, Feng Li*, Shilong Liu*, Lei Zhang, Hang Su, Jun Zhu, Lionel M. Ni, Heung-Yeung Shum.   
arxiv 2022.  
[[**Paper**]](https://arxiv.org/abs/2203.03605)[[**Code**]](https://github.com/IDEACVR/DINO)
  
* Vision-Language Intelligence: Tasks, Representation Learning, and Large Models.  
Feng Li*, Hao Zhang*, Yi-Fan Zhang, Shilong Liu, Jian Guo, Lionel M Ni, PengChuan Zhang, Lei Zhang.     
arxiv 2022.  
[[**Paper**]](https://arxiv.org/abs/2203.01922)      
  
* DN-DETR: Accelerate DETR Training by Introducing Query DeNoising.   
Feng Li*, Hao Zhang*, Shilong Liu, Jian Guo, Lionel M. Ni, Lei Zhang.   
IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2022.  
[[**Paper**]](https://arxiv.org/pdf/2203.01305)[[**Code**]](https://github.com/FengLi-ust/DN-DETR)
 
* DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR.   
Shilong Liu, Feng Li, Hao Zhang, Xiao Yang, Xianbiao Qi, Hang Su, Jun Zhu, Lei Zhang.    
International Conference on Learning Representations (ICLR) 2022.    
[[**Paper**]](https://arxiv.org/abs/2201.12329)[[**Code**]](https://github.com/SlongLiu/DAB-DETR)

* BiCrowd: Online Bi-Objective Incentive Mechanism for Mobile Crowd Sensing.   
Yi-Fan Zhang, Xinglin Zhang, and Feng Li. 
IEEE Internet of Things Journal (JCR Q1).  
[[**Paper**]](https://fengli-ust.github.io/files/BiCrowd-IOT-J.pdf)

<!-- </div>
</div> -->

_(* denotes equal contribution.)_
# üéñ Selected Awards
* Hong Kong Postgraduate Scholoarship, 2021
* Contemporary Undergraduate Mathematical Contest in Modeling(CUMCM), National first prize, 2019.

<!-- # üìñ Work experience
* March 2021 - Now: Research Assistant
  * Microsoft Research Asia, Beijing, China.
  * Duties included: 1. Design more powerful and simple object detection architecture based on the Transformer. 2. Understand NLP tasks such as NLI and exploit new paradigms to solve them more efficiently.
  * Advisor: Prof. [Jingdong Wang](https://jingdongwang2017.github.io/)

* August 2020 - Now: Research Assistant
  * University of Chinese Academy of Sciences, Beijing, China.
  * Duties included: 1. learning deep generative model for pedestrian generation. 2. cross-domain Re-ID from a causal view. 3. designing an efficient method to tackle problems in object detection and partial pedestrian re-identification.
  * Advisor: Prof. [Tieniu Tan](http://people.ucas.ac.cn/~tantieniu)
  * Co-Advisors: Prof. [Zhang Zhang](https://scholar.google.com/citations?user=rnRNwEMAAAAJ&hl=en) and Prof. [Liang Wang](https://scholar.google.com/citations?user=8kzzUboAAAAJ&hl=zh-CN)

* April 2018 ‚Äì July 2020: Research Assistant
  * South China University of Technology, Guangzhou, China.
  * Duties included: Incentive mechanism design for crowdsourcing platforms, edge computing
platforms, and federal learning platforms.
  * Advisor: Prof. Xinglin Zhang
 -->
<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->
